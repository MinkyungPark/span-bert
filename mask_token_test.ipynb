{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd175b5-1218-4cfe-b2f3-7c850c4e5e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "user_defined_symbols = ['[PAD]', '[UNK]', '[UNK0]','[UNK1]','[UNK2]','[UNK3]','[UNK4]','[UNK5]','[UNK6]','[UNK7]','[UNK8]','[UNK9]', '[CLS]', '[SEP]', '[MASK]', '[BOS]','[EOS]']\n",
    "unused_token_num = 200\n",
    "unused_list = ['[unused{}]'.format(n) for n in range(unused_token_num)]\n",
    "user_defined_symbols = user_defined_symbols + unused_list\n",
    "\n",
    "tokenizer = BertTokenizerFast(\n",
    "    vocab_file = './hf_tokenizer_special/vocab.txt',\n",
    "    max_len = 512,\n",
    "    do_lower_case=False,\n",
    ")\n",
    "\n",
    "special_token_dic = {'additional_special_tokens': user_defined_symbols}\n",
    "tokenizer.add_special_tokens(special_token_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c6b55d-d6b1-4a9d-8b79-d17ca91de2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model_output were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.24728845059871674,\n",
       "  'token': 7092,\n",
       "  'token_str': '아메리카노',\n",
       "  'sequence': '오늘 카페에가서 아메리카노 를 먹었는데요, 너무 맛있떠라구요.'},\n",
       " {'score': 0.1023724377155304,\n",
       "  'token': 6527,\n",
       "  'token_str': '커피',\n",
       "  'sequence': '오늘 카페에가서 커피 를 먹었는데요, 너무 맛있떠라구요.'},\n",
       " {'score': 0.04726902395486832,\n",
       "  'token': 8890,\n",
       "  'token_str': '아아',\n",
       "  'sequence': '오늘 카페에가서 아아 를 먹었는데요, 너무 맛있떠라구요.'},\n",
       " {'score': 0.040487710386514664,\n",
       "  'token': 6798,\n",
       "  'token_str': '디저트',\n",
       "  'sequence': '오늘 카페에가서 디저트 를 먹었는데요, 너무 맛있떠라구요.'},\n",
       " {'score': 0.038824670016765594,\n",
       "  'token': 10955,\n",
       "  'token_str': '팥빙수',\n",
       "  'sequence': '오늘 카페에가서 팥빙수 를 먹었는데요, 너무 맛있떠라구요.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load bert model\n",
    "from transformers import BertForMaskedLM, pipeline\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('model_output')\n",
    "nlp_fill = pipeline('fill-mask', top_k=5, model=model, tokenizer=tokenizer)\n",
    "nlp_fill('오늘 카페에가서 [MASK]를 먹었는데요, 너무 맛있떠라구요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969d77db-c24f-4e86-84fb-22edc3aef990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233658"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dbConn.mongo_conn import config\n",
    "\n",
    "conn = config()\n",
    "col = conn['travel_ai'].blog_contents\n",
    "\n",
    "test_set = list(col.find({\"num_docs\": {\"$gte\": 1, \"$lte\": 100}}, {\"cleaned_content\": 1}))\n",
    "conn.close()\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308149c9-050d-43d2-956b-763b91655c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4850590"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_set = []\n",
    "for t in test_set:\n",
    "    sentence_set.extend(t['cleaned_content'])\n",
    "del test_set\n",
    "sentence_set = list(set(sentence_set))\n",
    "len(sentence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dddfd741-12b8-4b57-852f-d3d5bd90318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 87\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "m = Mecab()\n",
    "\n",
    "test_set = random.sample(sentence_set, 100)\n",
    "origin_sent, masked_set = [], []\n",
    "for sentence in test_set:\n",
    "    nouns = []\n",
    "    for (word, pos) in m.pos(sentence):\n",
    "        if len(word) > 1 and pos == 'NNG' or pos == 'NNP':\n",
    "            nouns.append(word)\n",
    "    if len(nouns) > 1:\n",
    "        for trans_noun in random.sample(nouns, 1):\n",
    "            origin_sent.append(sentence)\n",
    "            masked_set.append(sentence.replace(trans_noun, '[MASK]'))\n",
    "del test_set\n",
    "print(len(origin_sent), len(origin_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee6215c-f538-44b9-a811-6a23fd14b54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대문짝만하게 모노하라고 써있지는 않음카카오맵보고 찾아가는데 어디가 문짝인지 몰라서 허둥허둥안에서 보기엔 좀 웃겼을 듯 논픽션 애깅이들 VMD 굿~ 논픽션 제품을 오프라인에서 볼 수 있는 곳이몇몇군데 있는 것으로 알고 있는데.\n",
      "[MASK]만하게 모노하라고 써있지는 않음카카오맵보고 찾아가는데 어디가 문짝인지 몰라서 허둥허둥안에서 보기엔 좀 웃겼을 듯 논픽션 애깅이들 VMD 굿~ 논픽션 제품을 오프라인에서 볼 수 있는 곳이몇몇군데 있는 것으로 알고 있는데.\n"
     ]
    }
   ],
   "source": [
    "test_num = 33\n",
    "print(origin_sent[test_num])\n",
    "print(masked_set[test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dcfa216-76a3-419b-8080-1fc8ba737528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "df_result = []\n",
    "for sent, masked_sent in zip(origin_sent, masked_set):\n",
    "    score, token_str, sequence = [], [], []\n",
    "    masked_preds = nlp_fill(masked_sent)\n",
    "    if type(masked_preds[0]) != list:\n",
    "        for mask_pred in masked_preds:\n",
    "            if re.search(u'[가-힣]', mask_pred['token_str']):\n",
    "                score.append(str(mask_pred['score']))\n",
    "                token_str.append(mask_pred['token_str'])\n",
    "                sequence.append(mask_pred['sequence'])\n",
    "        if score:\n",
    "            df_result.append((sent, masked_sent, '\\n'.join(score), '\\n'.join(token_str), '\\n'.join(sequence)))\n",
    "    else:\n",
    "        for masked_pred_list in masked_preds:\n",
    "            for masked_pred in masked_pred_list:\n",
    "                if re.search(u'[가-힣]', masked_pred['token_str']):\n",
    "                    score.append(str(masked_pred['score']))\n",
    "                    token_str.append(masked_pred['token_str'])\n",
    "                    sequence.append(masked_pred['sequence'])\n",
    "        if score:\n",
    "            df_result.append((sent, masked_sent, '\\n'.join(score), '\\n'.join(token_str), '\\n'.join(sequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19448d3e-d3b3-46a8-8bf7-d51bbd2e1d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_sentence</th>\n",
       "      <th>masked_sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>pred_word</th>\n",
       "      <th>pred_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!뭐 대...</td>\n",
       "      <td>와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!뭐 대...</td>\n",
       "      <td>0.056007735431194305\\n0.050780776888132095\\n0....</td>\n",
       "      <td>난리\\n말\\n메뉴판</td>\n",
       "      <td>와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E! N! G! L! I! S!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!뭐 대...</td>\n",
       "      <td>와인 [MASK]가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!...</td>\n",
       "      <td>0.5364090800285339\\n0.12141339480876923\\n0.041...</td>\n",
       "      <td>##바\\n바\\n리스트\\n메뉴\\n아틀리에</td>\n",
       "      <td>와인바 가 있어서와알못은잠시 정독중인 척 해보지만E! N! G! L! I! S! H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백질 보충!</td>\n",
       "      <td>같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 [MASK]...</td>\n",
       "      <td>0.13839229941368103\\n0.06216518580913544\\n0.03...</td>\n",
       "      <td>체력\\n기력\\n탄수화물\\n단백질\\n##시기</td>\n",
       "      <td>같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 체력 보충!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백질 보충!</td>\n",
       "      <td>같이 간 지인은 중간 [MASK]이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백...</td>\n",
       "      <td>0.33190852403640747\\n0.0823947861790657\\n0.066...</td>\n",
       "      <td>##맛\\n##에\\n맛</td>\n",
       "      <td>같이 간 지인은 중간맛 이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백질 보충!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여기서 기억에 남는 커피는다 맛있지만엘카미노가 기억에 오래 남을 블렌딩커피 같네요쓴...</td>\n",
       "      <td>여기서 [MASK]에 남는 커피는다 맛있지만엘카미노가 [MASK]에 오래 남을 블렌...</td>\n",
       "      <td>0.23676477372646332\\n0.0807899683713913\\n0.080...</td>\n",
       "      <td>기억\\n끝\\n아쉬움\\n마지막\\n여운\\n커피\\n기억\\n마지막</td>\n",
       "      <td>[CLS] 여기서 기억 에 남는 커피는다 맛있지만엘카미노가 [MASK] 에 오래 남...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     origin_sentence  \\\n",
       "0  와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!뭐 대...   \n",
       "1  와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!뭐 대...   \n",
       "2    같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백질 보충!   \n",
       "3    같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백질 보충!   \n",
       "4  여기서 기억에 남는 커피는다 맛있지만엘카미노가 기억에 오래 남을 블렌딩커피 같네요쓴...   \n",
       "\n",
       "                                     masked_sentence  \\\n",
       "0  와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!뭐 대...   \n",
       "1  와인 [MASK]가 있어서와알못은잠시 정독중인 척 해보지만E!N!G!L!I!S!H!...   \n",
       "2  같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 [MASK]...   \n",
       "3  같이 간 지인은 중간 [MASK]이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백...   \n",
       "4  여기서 [MASK]에 남는 커피는다 맛있지만엘카미노가 [MASK]에 오래 남을 블렌...   \n",
       "\n",
       "                                               score  \\\n",
       "0  0.056007735431194305\\n0.050780776888132095\\n0....   \n",
       "1  0.5364090800285339\\n0.12141339480876923\\n0.041...   \n",
       "2  0.13839229941368103\\n0.06216518580913544\\n0.03...   \n",
       "3  0.33190852403640747\\n0.0823947861790657\\n0.066...   \n",
       "4  0.23676477372646332\\n0.0807899683713913\\n0.080...   \n",
       "\n",
       "                          pred_word  \\\n",
       "0                        난리\\n말\\n메뉴판   \n",
       "1             ##바\\n바\\n리스트\\n메뉴\\n아틀리에   \n",
       "2           체력\\n기력\\n탄수화물\\n단백질\\n##시기   \n",
       "3                       ##맛\\n##에\\n맛   \n",
       "4  기억\\n끝\\n아쉬움\\n마지막\\n여운\\n커피\\n기억\\n마지막   \n",
       "\n",
       "                                       pred_sentence  \n",
       "0  와인 가이드가 있어서와알못은잠시 정독중인 척 해보지만E! N! G! L! I! S!...  \n",
       "1  와인바 가 있어서와알못은잠시 정독중인 척 해보지만E! N! G! L! I! S! H...  \n",
       "2  같이 간 지인은 중간 부분이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 체력 보충!...  \n",
       "3  같이 간 지인은 중간맛 이 살짝 질기긴한데이정도면 괜찮다고 맛있다함뭐 단백질 보충!...  \n",
       "4  [CLS] 여기서 기억 에 남는 커피는다 맛있지만엘카미노가 [MASK] 에 오래 남...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_result, columns=['origin_sentence', 'masked_sentence', 'score', 'pred_word', 'pred_sentence'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd2c483-a5bd-4c3b-9d8a-1b1ee890379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./masked_word_pred.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5675eda0-e803-4870-93ab-77ce41f45ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = '해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. [MASK]하게 잘 익고 있는거 보이시나요?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ef750dc-32bf-487a-9dea-32c2f089d3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. [MASK]하게 잘 익고 있는거 보이시나요?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6487979292869568,\n",
       "  'token': 9029,\n",
       "  'token_str': '노릇노릇',\n",
       "  'sequence': '해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. 노릇노릇 하게 잘 익고 있는거 보이시나요?'},\n",
       " {'score': 0.07009831070899963,\n",
       "  'token': 8388,\n",
       "  'token_str': '노릇',\n",
       "  'sequence': '해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. 노릇 하게 잘 익고 있는거 보이시나요?'},\n",
       " {'score': 0.027685485780239105,\n",
       "  'token': 9486,\n",
       "  'token_str': '지글지글',\n",
       "  'sequence': '해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. 지글지글 하게 잘 익고 있는거 보이시나요?'},\n",
       " {'score': 0.018906276673078537,\n",
       "  'token': 9049,\n",
       "  'token_str': '야들야들',\n",
       "  'sequence': '해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. 야들야들 하게 잘 익고 있는거 보이시나요?'},\n",
       " {'score': 0.012451782822608948,\n",
       "  'token': 11800,\n",
       "  'token_str': '꼬들꼬들',\n",
       "  'sequence': '해돋이펜션에서는 2만원만 추가하면 바베큐를 이용할 수 있어요. 꼬들꼬들 하게 잘 익고 있는거 보이시나요?'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t)\n",
    "nlp_fill(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2352bdec-139d-4282-b718-f0e44a3f4e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정말 [MASK]한 가격에 질 좋은 고기를 맛볼수 있는 이곳!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3683983087539673,\n",
       "  'token': 6856,\n",
       "  'token_str': '저렴',\n",
       "  'sequence': '정말 저렴 한 가격에 질 좋은 고기를 맛볼수 있는 이곳!'},\n",
       " {'score': 0.16905361413955688,\n",
       "  'token': 7997,\n",
       "  'token_str': '착한',\n",
       "  'sequence': '정말 착한 한 가격에 질 좋은 고기를 맛볼수 있는 이곳!'},\n",
       " {'score': 0.05537271872162819,\n",
       "  'token': 6490,\n",
       "  'token_str': '정말',\n",
       "  'sequence': '정말 정말 한 가격에 질 좋은 고기를 맛볼수 있는 이곳!'},\n",
       " {'score': 0.03767986595630646,\n",
       "  'token': 2738,\n",
       "  'token_str': '이',\n",
       "  'sequence': '정말 이 한 가격에 질 좋은 고기를 맛볼수 있는 이곳!'},\n",
       " {'score': 0.021080244332551956,\n",
       "  'token': 75,\n",
       "  'token_str': '~',\n",
       "  'sequence': '정말 ~ 한 가격에 질 좋은 고기를 맛볼수 있는 이곳!'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t)\n",
    "nlp_fill(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8b9b383-9fdf-4944-bd9b-ad3acf951b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼각지에 요즘 핫하다는 내추럴 [MASK] 먹으러 갔다왔어요. 쿰쿰한 맛이 정말 매력적이랍니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5964204668998718,\n",
       "  'token': 6747,\n",
       "  'token_str': '와인',\n",
       "  'sequence': '삼각지에 요즘 핫하다는 내추럴 와인 먹으러 갔다왔어요. 쿰쿰한 맛이 정말 매력적이랍니다.'},\n",
       " {'score': 0.3033031225204468,\n",
       "  'token': 12286,\n",
       "  'token_str': '##와인',\n",
       "  'sequence': '삼각지에 요즘 핫하다는 내추럴와인 먹으러 갔다왔어요. 쿰쿰한 맛이 정말 매력적이랍니다.'},\n",
       " {'score': 0.01330279465764761,\n",
       "  'token': 13029,\n",
       "  'token_str': '레드와인',\n",
       "  'sequence': '삼각지에 요즘 핫하다는 내추럴 레드와인 먹으러 갔다왔어요. 쿰쿰한 맛이 정말 매력적이랍니다.'},\n",
       " {'score': 0.007578785065561533,\n",
       "  'token': 11902,\n",
       "  'token_str': '위스키',\n",
       "  'sequence': '삼각지에 요즘 핫하다는 내추럴 위스키 먹으러 갔다왔어요. 쿰쿰한 맛이 정말 매력적이랍니다.'},\n",
       " {'score': 0.0028995973989367485,\n",
       "  'token': 9876,\n",
       "  'token_str': '하이볼',\n",
       "  'sequence': '삼각지에 요즘 핫하다는 내추럴 하이볼 먹으러 갔다왔어요. 쿰쿰한 맛이 정말 매력적이랍니다.'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t)\n",
    "nlp_fill(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
