{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0fc764e-6959-4698-adeb-df59f078c34e",
   "metadata": {},
   "source": [
    "model로드시 pretraine 때 사용했던 토크나이저를 그대로 사용해야 벡터 변환에 문제가 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95b07b2-4410-425d-98e5-93a0fe4c682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_symbols = ['[PAD]', '[UNK]', '[UNK0]','[UNK1]','[UNK2]','[UNK3]','[UNK4]','[UNK5]','[UNK6]','[UNK7]','[UNK8]','[UNK9]', '[CLS]', '[SEP]', '[MASK]', '[BOS]','[EOS]']\n",
    "unused_token_num = 200\n",
    "unused_list = ['[unused{}]'.format(n) for n in range(unused_token_num)]\n",
    "user_defined_symbols = user_defined_symbols + unused_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cb9a90-ddaf-4136-beac-d20226a1c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '은', '[MASK]', '엄청', '맛있', '##었', '##고', '촉촉', '##하고', '바삭', '##했', '##어요', '.']\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast(\n",
    "    vocab_file = './hf_tokenizer_special/vocab.txt',\n",
    "    max_len = 128,\n",
    "    do_lower_case=False,\n",
    ")\n",
    "\n",
    "special_token_dic = {'additional_special_tokens': user_defined_symbols}\n",
    "tokenizer.add_special_tokens(special_token_dic)\n",
    "print(tokenizer.tokenize('曔은 [MASK] 엄청 맛있었고 촉촉하고 바삭했어요.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b550a063-3b0f-4e93-ba86-769954930a7c",
   "metadata": {},
   "source": [
    "### Input Formatting\n",
    "- special token[sep]은 문장의 끝을 표시하거나 두 문장의 분리할 때 사용한다.\n",
    "- special token[CLS]은 문장 시작할 때 사용한다. 이 토큰은 분류 문제에 사용되지만, 어떤 문제를 풀더라도 입력해야한다.\n",
    "- BERT에서 사용되는 단어사전에 있는 토큰\n",
    "- BERT 토크 나이저의 토큰에 대한 Token ID\n",
    "- 시퀀스에서 어떤 요소가 토큰이고 패딩 요소인지를 나타내는 Mask ID\n",
    "- 다른 문장을 구별하는데 사용되는 Segment ID\n",
    "- 시퀀스 내에서 토큰 위치를 표시하는 데 사용되는 Positional Embeddings <br>\n",
    "tokenizer\n",
    "tokenize.encode_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb8e166-91d7-4ffe-8e43-39149fa9dbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: [CLS], index: 2\n",
      "token: 오늘, index: 6520\n",
      "token: 서촌, index: 26906\n",
      "token: ##에, index: 4444\n",
      "token: 갔다, index: 9930\n",
      "token: ##가, index: 4391\n",
      "token: 복숭아, index: 10138\n",
      "token: 요거, index: 7991\n",
      "token: ##트, index: 4189\n",
      "token: ##를, index: 4633\n",
      "token: 먹, index: 1441\n",
      "token: ##었, index: 4229\n",
      "token: ##어요, index: 6682\n",
      "token: ., index: 9\n",
      "token: 우연히, index: 9084\n",
      "token: 들어간, index: 7153\n",
      "token: 곳, index: 195\n",
      "token: ##이, index: 4196\n",
      "token: ##었, index: 4229\n",
      "token: ##는데, index: 9223\n",
      "token: 정말, index: 6490\n",
      "token: 맛있, index: 6474\n",
      "token: ##었, index: 4229\n",
      "token: ##답니다, index: 7219\n",
      "token: ., index: 9\n",
      "token: [SEP], index: 3\n"
     ]
    }
   ],
   "source": [
    "test_txt = \"[CLS]오늘 서촌에 갔다가 복숭아 요거트를 먹었어요. 우연히 들어간 곳이었는데 정말 맛있었답니다.[SEP]\"\n",
    "tokened_txt = tokenizer.tokenize(test_txt)\n",
    "indexed_txt = tokenizer.convert_tokens_to_ids(tokened_txt)\n",
    "for t, i in zip(tokened_txt, indexed_txt):\n",
    "    print(f'token: {t}, index: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857a50a1-f3ac-402f-bb2e-e46a76fd6ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segements_ids = []\n",
    "seg_num = 1\n",
    "for token in tokened_txt:\n",
    "    segements_ids.append(seg_num)\n",
    "    if token == \"[SEP]\":\n",
    "        seg_num -= 1\n",
    "print(segements_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca76fc-0d1a-4112-9158-34d61333750b",
   "metadata": {},
   "source": [
    "bert pytorch interface에서는 데이터 형태가 python list(X)<br>\n",
    "데이터를 torch tensor로 변환하고 BERT model call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a4fcb4-d300-4e45-b7d8-2a3d73fadaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# convert inputs to torch tensor\n",
    "token_tensor = torch.tensor([indexed_txt])\n",
    "segments_tensors = torch.tensor([segements_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9644abf-4ec6-44e9-9faf-96c10cddc5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model_output were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"model_output\",\n",
       "  \"architectures\": [\n",
       "    \"BertForPreTraining\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embedding\": 128,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.15.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model load\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "pretrained_model_config = BertConfig.from_pretrained('model_output')\n",
    "\n",
    "my_model = BertModel.from_pretrained(\n",
    "    'model_output', \n",
    "    # output_hidden_states=True,\n",
    "    config=pretrained_model_config\n",
    ")\n",
    "pretrained_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cfde240-a938-4a2c-a565-88c4c31a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()은 평가 모드로 모델 선정, 드롭아웃 해제\n",
    "# torch.no_grad()는 forward만, backprop하지 X 메모리랑 속도 \n",
    "with torch.no_grad():\n",
    "    outputs = my_model(token_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216e718-e4e1-4b3d-9cea-84109736d261",
   "metadata": {},
   "source": [
    "- outputs[2]\n",
    "    - 문장이 각각 768 차원 벡터로 변환된 것.\n",
    "    - Bert 마지막 레이어의 CLS 벡터들\n",
    "    - 문장 전체를 벡터 하나로 변환한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc731f-2716-44df-87d4-8d9d69f1af98",
   "metadata": {},
   "source": [
    "### outputs\n",
    "- 모델의 여러 출력 결과를 한데 묶은 것\n",
    "- hidden_states 개체의 저장된 모델의 전체 은닉층은 4개의 차원이 존재\n",
    "1. The **layer** number (13 layers) bert 12 layers + 1 input embedding\n",
    "2. The **batch** number (1 sentence)\n",
    "3. The word / **token** number (36 tokens in our sentence)\n",
    "4. The hidden unit / **feature** number (768 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb666825-67ce-4df5-b4cb-93a6056e6572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 26\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "# 현재 차원 [layers, batches, tokens, features]\n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70bdaf5-eb7d-40f1-a803-aaad07bdd385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 26, 768])\n"
     ]
    }
   ],
   "source": [
    "# 차원을 [tokens, layers, features]로 만든다. permute 함수 이용\n",
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60ad008-d935-4f94-aff9-3c1e179404d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 26, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size() # [layers, batches, tokens, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55fa1365-c971-43af-b7fe-6ac8d8fb1add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 26, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eadd460a-5f2e-432a-b605-405c1f103e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 13, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size() # [tokens, layers, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98527e96-275a-4fcd-9cda-114e14b598c5",
   "metadata": {},
   "source": [
    "need to extract each vector of tokens or whole vector of sentence <br>\n",
    "but we have hidden states and 768 size 13 vector per each 26 tokens(26개 토큰에 대해 768크기의 13개 개별 벡터) <br>\n",
    "개별 벡터를 얻으려면 일부 레이어 벡터를 결합해야 한다. <br>\n",
    "결합에 있어 레이어 조합에 관한 최상의 표현 방법은 정해지지 않았음. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84a15798-09e5-4830-b70d-e22c61f8f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 26 x 3072\n"
     ]
    }
   ],
   "source": [
    "# Token vector\n",
    "# 1. 마지막 4개의 레이어를 concatenate하여 토큰 당 단일 단어 벡터를 제공.\n",
    "# 각 벡터의 길이 4*768 = 3,072\n",
    "token_vecs_cat = []\n",
    "for token in token_embeddings:\n",
    "    # 1 token -> [12*768], [26*12*768]\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12f32e1c-630c-4555-aff9-ea4f024d7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 26 x 768\n"
     ]
    }
   ],
   "source": [
    "# 2. 마지막 4개의 레이어를 합산(sum)하여 단어 벡터를 만듬.\n",
    "token_vecs_sum = []\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "    \n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fad23fd-f9c0-4252-8c99-5ae0e4a20af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2208, -0.5151])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Vector\n",
    "# 1. 토큰별 768크기의 벡터를 생성하는 각 토큰의 두번째에서 마지막 숨겨진 레이어의 평균을 내는 것\n",
    "# hidden_states -> [13x1x26x768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "# the avg of all 26 token vectors\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "sentence_embedding[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebbd0df0-45af-40c9-8015-5dafdccca8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43318aa8-cfc8-4c4e-a10b-221a48cb4a00",
   "metadata": {},
   "source": [
    "### word embed\n",
    "1. last_hidden_state = outputs\\[0\\]\n",
    "    - word_embed_1 = last_hidden_state\n",
    "2. initial embeddings can be taken from 0th layer of hidden states\n",
    "    - word_embed_2 = hidden_states\\[0\\]\n",
    "3. sum of all hidden states\n",
    "    - word_embed_3 = torch.stack(hidden_states).sum(0)\n",
    "4. sum of second to last layer\n",
    "    - word_embed_4 = torch.stack(hidden_states\\[2:\\]).sum(0)\n",
    "5. sum of last four layer\n",
    "    - word_embed_5 = torch.stack(hidden_states\\[-4:\\]).sum(0)\n",
    "6. concatenate last four layers\n",
    "    - word_embed_6 = torch.cat(\\[hidden_states[i\\] for i in \\[-1,-2,-3,-4\\]\\], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "41668035-703e-4475-b047-fedcbc9c84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_vec_sum(model, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt') # input_ids, token_type_ids(segement info), attention_mask(padding token)\n",
    "    model.eval()\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    hidden_states = outputs.last_hidden_state # or outpus[0]\n",
    "    token_embeddings = hidden_states.permute(1,0,2)\n",
    "    \n",
    "    token_vecs_sum = []\n",
    "    for token in token_embeddings:\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        token_vecs_sum.append(sum_vec)\n",
    "    # 마지막 4개 레이어 합산한 벡터값\n",
    "    return inputs, token_vecs_sum # size : (token 갯수, 768 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3167cb50-a430-4a31-95fe-f9adad9a79c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 768\n",
      "12 768\n",
      "0 ('[CLS]', tensor(2))\n",
      "1 ('밤', tensor(1624))\n",
      "2 ('몽블랑', tensor(18026))\n",
      "3 ('먹', tensor(1441))\n",
      "4 ('##었', tensor(4229))\n",
      "5 ('##는데', tensor(9223))\n",
      "6 ('너무', tensor(6479))\n",
      "7 ('맛있', tensor(6474))\n",
      "8 ('##네요', tensor(18605))\n",
      "9 ('.', tensor(9))\n",
      "10 ('[SEP]', tensor(3))\n",
      "\n",
      "0 ('[CLS]', tensor(2))\n",
      "1 ('바', tensor(1611))\n",
      "2 ('##밤', tensor(5030))\n",
      "3 ('##바', tensor(4298))\n",
      "4 ('##보다', tensor(29998))\n",
      "5 ('맛있', tensor(6474))\n",
      "6 ('##는', tensor(4214))\n",
      "7 ('왕', tensor(2594))\n",
      "8 ('##밤', tensor(5030))\n",
      "9 ('##빵', tensor(4738))\n",
      "10 ('.', tensor(9))\n",
      "11 ('[SEP]', tensor(3))\n"
     ]
    }
   ],
   "source": [
    "# 상황별 토큰 벡터 비교\n",
    "t1 = \"밤 몽블랑 먹었는데 너무 맛있네요.\"\n",
    "t2 = \"바밤바보다 맛있는 왕밤빵.\"\n",
    "t1_tokens = tokenizer.tokenize(\"[CLS]\" + t1 + \"[SEP]\")\n",
    "t2_tokens = tokenizer.tokenize(\"[CLS]\" + t2 + \"[SEP]\")\n",
    "\n",
    "input_t1, token_vec_sum_t1 = get_token_vec_sum(my_model, t1)\n",
    "input_t2, token_vec_sum_t2 = get_token_vec_sum(my_model, t2)\n",
    "print(len(token_vec_sum_t1), len(token_vec_sum_t1[0])) # (token갯수+[CLS][SEP]토큰2개, 768 features)\n",
    "print(len(token_vec_sum_t2), len(token_vec_sum_t2[0]))\n",
    "\n",
    "for i, token_id in enumerate(zip(t1_tokens, input_t1['input_ids'][0])):\n",
    "    print(i, token_id)\n",
    "print()\n",
    "for i, token_id in enumerate(zip(t2_tokens, input_t2['input_ids'][0])):\n",
    "    print(i, token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e609279-0c7f-4007-86de-6ca984b0b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "밤으로 만든 몽블랑 먹었는데 너무 맛있네요. 의 '밤'(#1)\n",
      "-> tensor([ 1.0066, -1.2224,  0.2787, -0.1907, -0.0580], grad_fn=<SliceBackward>)\n",
      "바밤바가 너무 맛있어 의 '밤'(#8)\n",
      "-> tensor([-0.5164, -1.8232,  1.4110, -1.2231, -2.3583], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{t1} 의 '밤'(#1)\\n-> {token_vec_sum_t1[1][:5]}\") # 768 중 5개까지만 확인\n",
    "print(f\"{t2} 의 '밤'(#8)\\n-> {token_vec_sum_t2[5][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "713bb909-983d-4dfe-8037-633c41f8d4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5491033792495728"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Consine similarity 비교\n",
    "sim_word = cosine(token_vec_sum_t1[1].detach().numpy(), token_vec_sum_t2[8].detach().numpy())\n",
    "sim_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
